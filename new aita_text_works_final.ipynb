{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "931c9981-47f7-4d3a-8b7c-4d64e8a40f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install spacy\n",
    "# !pip install nltk\n",
    "# !pip install tensorflow\n",
    "# !pip install python-Levenshtein\n",
    "# !pip install textblob\n",
    "# !pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4b59456-1ef9-43ea-a408-a5c6ae57da27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "     --------------------------------------- 12.8/12.8 MB 72.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: setuptools in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (21.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.23.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.11.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.12)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.1)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     \\\\files.kent.ac.uk\\usersk\\ko275\\home\\Essential-User-\n",
      "[nltk_data]     Settings\\AppData\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cd8b0ad-59d7-4962-ad7b-dbc2675c34d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from textblob import TextBlob\n",
    "import Levenshtein\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20bbbd51-1098-4d4e-bd58-34aca165f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['tagger', 'parser', 'ner'])\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Load the data\n",
    "\n",
    "df = pd.read_csv('X:/home/aita_clean.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "\n",
    "# Filter the data for each class\n",
    "class_0 = df[df['is_asshole'] == 0]\n",
    "class_1 = df[df['is_asshole'] == 1]\n",
    "\n",
    "# Sample an equal number of instances from each class\n",
    "sample_size = 25000\n",
    "class_0_sample = class_0.samGGple(sample_size, random_state=42)\n",
    "class_1_sample = class_1.sample(sample_size, random_state=42)\n",
    "\n",
    "# Combine the sampled data and shuffle it\n",
    "df = pd.concat([class_0_sample, class_1_sample]).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33d83ca-17f7-49d9-bcaa-c43445dd91ca",
   "metadata": {},
   "source": [
    "This code preprocesses a dataset of titles and bodies, tokenizes the text, and trains a multi-task seq2seq model to generate titles and bodies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077f81c5-c854-471a-9246-b3720c6c7a6f",
   "metadata": {},
   "source": [
    "The script involves preprocessing of text data, creation of sequences from preprocessed data, tokenization, splitting the data into training and validation sets, and defining and training a multi-task learning model. The model consists of an encoder and two decoders (one for the title and one for the body) and is trained to generate text for both title and body simultaneously. Inference models are defined for each decoder to generate new text. The script implements multi-task learning for text generation using seq2seq architecture with LSTM units.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae3da236-bbdf-4e68-9998-ca15e7d0e39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing start token in 0 sequences.\n",
      "Missing end token in 0 sequences.\n",
      "Missing separator token in 0 sequences.\n",
      "X_train_title shape: (17895, 20)\n",
      "X_train_body shape: (17895, 200)\n",
      "Epoch 1/50\n",
      "504/504 [==============================] - 9091s 18s/step - loss: 5.2175 - time_distributed_loss: 3.9968 - time_distributed_1_loss: 6.4382 - val_loss: 4.5302 - val_time_distributed_loss: 3.2653 - val_time_distributed_1_loss: 5.7951\n",
      "Epoch 2/50\n",
      "504/504 [==============================] - 9543s 19s/step - loss: 4.1909 - time_distributed_loss: 2.9958 - time_distributed_1_loss: 5.3860 - val_loss: 4.1008 - val_time_distributed_loss: 2.9935 - val_time_distributed_1_loss: 5.2082\n",
      "Epoch 3/50\n",
      "504/504 [==============================] - 9398s 19s/step - loss: 3.8860 - time_distributed_loss: 2.7592 - time_distributed_1_loss: 5.0129 - val_loss: 3.9428 - val_time_distributed_loss: 2.8823 - val_time_distributed_1_loss: 5.0033\n",
      "Epoch 4/50\n",
      "504/504 [==============================] - 9285s 18s/step - loss: 3.7140 - time_distributed_loss: 2.6128 - time_distributed_1_loss: 4.8152 - val_loss: 3.8518 - val_time_distributed_loss: 2.8274 - val_time_distributed_1_loss: 4.8762\n",
      "Epoch 5/50\n",
      "504/504 [==============================] - 9483s 19s/step - loss: 3.5835 - time_distributed_loss: 2.5003 - time_distributed_1_loss: 4.6666 - val_loss: 3.7897 - val_time_distributed_loss: 2.7943 - val_time_distributed_1_loss: 4.7851\n",
      "Epoch 6/50\n",
      "504/504 [==============================] - 9557s 19s/step - loss: 3.4671 - time_distributed_loss: 2.3869 - time_distributed_1_loss: 4.5473 - val_loss: 3.7314 - val_time_distributed_loss: 2.7442 - val_time_distributed_1_loss: 4.7186\n",
      "Epoch 7/50\n",
      "504/504 [==============================] - 9777s 19s/step - loss: 3.3578 - time_distributed_loss: 2.2722 - time_distributed_1_loss: 4.4435 - val_loss: 3.6740 - val_time_distributed_loss: 2.6845 - val_time_distributed_1_loss: 4.6634\n",
      "Epoch 8/50\n",
      "504/504 [==============================] - 9660s 19s/step - loss: 3.2411 - time_distributed_loss: 2.1322 - time_distributed_1_loss: 4.3499 - val_loss: 3.6167 - val_time_distributed_loss: 2.6150 - val_time_distributed_1_loss: 4.6184\n",
      "Epoch 9/50\n",
      "504/504 [==============================] - 9179s 18s/step - loss: 3.1387 - time_distributed_loss: 2.0109 - time_distributed_1_loss: 4.2666 - val_loss: 3.5844 - val_time_distributed_loss: 2.5809 - val_time_distributed_1_loss: 4.5879\n",
      "Epoch 10/50\n",
      "504/504 [==============================] - 9112s 18s/step - loss: 3.0480 - time_distributed_loss: 1.9043 - time_distributed_1_loss: 4.1918 - val_loss: 3.5563 - val_time_distributed_loss: 2.5511 - val_time_distributed_1_loss: 4.5615\n",
      "Epoch 11/50\n",
      "504/504 [==============================] - 9162s 18s/step - loss: 2.9628 - time_distributed_loss: 1.8028 - time_distributed_1_loss: 4.1228 - val_loss: 3.5381 - val_time_distributed_loss: 2.5327 - val_time_distributed_1_loss: 4.5436\n",
      "Epoch 12/50\n",
      "504/504 [==============================] - 9111s 18s/step - loss: 2.8820 - time_distributed_loss: 1.7052 - time_distributed_1_loss: 4.0588 - val_loss: 3.5267 - val_time_distributed_loss: 2.5218 - val_time_distributed_1_loss: 4.5316\n",
      "Epoch 13/50\n",
      "504/504 [==============================] - 9018s 18s/step - loss: 2.8069 - time_distributed_loss: 1.6147 - time_distributed_1_loss: 3.9991 - val_loss: 3.5211 - val_time_distributed_loss: 2.5213 - val_time_distributed_1_loss: 4.5209\n",
      "Epoch 14/50\n",
      "504/504 [==============================] - 9098s 18s/step - loss: 2.7381 - time_distributed_loss: 1.5331 - time_distributed_1_loss: 3.9431 - val_loss: 3.5206 - val_time_distributed_loss: 2.5229 - val_time_distributed_1_loss: 4.5183\n",
      "Epoch 15/50\n",
      "504/504 [==============================] - 9057s 18s/step - loss: 2.6740 - time_distributed_loss: 1.4577 - time_distributed_1_loss: 3.8902 - val_loss: 3.5185 - val_time_distributed_loss: 2.5208 - val_time_distributed_1_loss: 4.5163\n",
      "Epoch 16/50\n",
      "504/504 [==============================] - 9101s 18s/step - loss: 2.6139 - time_distributed_loss: 1.3876 - time_distributed_1_loss: 3.8403 - val_loss: 3.5241 - val_time_distributed_loss: 2.5303 - val_time_distributed_1_loss: 4.5178\n",
      "Epoch 17/50\n",
      "504/504 [==============================] - 9089s 18s/step - loss: 2.5584 - time_distributed_loss: 1.3235 - time_distributed_1_loss: 3.7933 - val_loss: 3.5314 - val_time_distributed_loss: 2.5411 - val_time_distributed_1_loss: 4.5216\n",
      "Epoch 18/50\n",
      "504/504 [==============================] - 9148s 18s/step - loss: 2.5069 - time_distributed_loss: 1.2647 - time_distributed_1_loss: 3.7491 - val_loss: 3.5378 - val_time_distributed_loss: 2.5495 - val_time_distributed_1_loss: 4.5261\n",
      "Epoch 19/50\n",
      "504/504 [==============================] - 9017s 18s/step - loss: 2.4579 - time_distributed_loss: 1.2090 - time_distributed_1_loss: 3.7068 - val_loss: 3.5459 - val_time_distributed_loss: 2.5597 - val_time_distributed_1_loss: 4.5321\n",
      "Epoch 20/50\n",
      "504/504 [==============================] - 9171s 18s/step - loss: 2.4115 - time_distributed_loss: 1.1561 - time_distributed_1_loss: 3.6669 - val_loss: 3.5587 - val_time_distributed_loss: 2.5780 - val_time_distributed_1_loss: 4.5394\n",
      "Epoch 21/50\n",
      "504/504 [==============================] - 8987s 18s/step - loss: 2.3676 - time_distributed_loss: 1.1067 - time_distributed_1_loss: 3.6286 - val_loss: 3.5684 - val_time_distributed_loss: 2.5910 - val_time_distributed_1_loss: 4.5457\n",
      "Epoch 22/50\n",
      "504/504 [==============================] - 9079s 18s/step - loss: 2.3253 - time_distributed_loss: 1.0587 - time_distributed_1_loss: 3.5918 - val_loss: 3.5775 - val_time_distributed_loss: 2.5993 - val_time_distributed_1_loss: 4.5557\n",
      "Epoch 23/50\n",
      "504/504 [==============================] - 9086s 18s/step - loss: 2.2849 - time_distributed_loss: 1.0129 - time_distributed_1_loss: 3.5570 - val_loss: 3.5900 - val_time_distributed_loss: 2.6133 - val_time_distributed_1_loss: 4.5666\n",
      "Epoch 24/50\n",
      "504/504 [==============================] - 9131s 18s/step - loss: 2.2461 - time_distributed_loss: 0.9692 - time_distributed_1_loss: 3.5230 - val_loss: 3.6026 - val_time_distributed_loss: 2.6289 - val_time_distributed_1_loss: 4.5762\n",
      "Epoch 25/50\n",
      "504/504 [==============================] - 9113s 18s/step - loss: 2.2097 - time_distributed_loss: 0.9285 - time_distributed_1_loss: 3.4910 - val_loss: 3.6188 - val_time_distributed_loss: 2.6503 - val_time_distributed_1_loss: 4.5872\n",
      "Epoch 26/50\n",
      "504/504 [==============================] - 9097s 18s/step - loss: 2.1740 - time_distributed_loss: 0.8881 - time_distributed_1_loss: 3.4600 - val_loss: 3.6326 - val_time_distributed_loss: 2.6647 - val_time_distributed_1_loss: 4.6005\n",
      "Epoch 27/50\n",
      "504/504 [==============================] - 9078s 18s/step - loss: 2.1403 - time_distributed_loss: 0.8503 - time_distributed_1_loss: 3.4303 - val_loss: 3.6472 - val_time_distributed_loss: 2.6842 - val_time_distributed_1_loss: 4.6102\n",
      "Epoch 28/50\n",
      "504/504 [==============================] - 9040s 18s/step - loss: 2.1070 - time_distributed_loss: 0.8124 - time_distributed_1_loss: 3.4017 - val_loss: 3.6576 - val_time_distributed_loss: 2.6931 - val_time_distributed_1_loss: 4.6222\n",
      "Epoch 29/50\n",
      "504/504 [==============================] - 9091s 18s/step - loss: 2.0751 - time_distributed_loss: 0.7762 - time_distributed_1_loss: 3.3740 - val_loss: 3.6779 - val_time_distributed_loss: 2.7170 - val_time_distributed_1_loss: 4.6388\n",
      "Epoch 30/50\n",
      "504/504 [==============================] - 9099s 18s/step - loss: 2.0444 - time_distributed_loss: 0.7419 - time_distributed_1_loss: 3.3470 - val_loss: 3.6925 - val_time_distributed_loss: 2.7355 - val_time_distributed_1_loss: 4.6495\n",
      "Epoch 31/50\n",
      "504/504 [==============================] - 9068s 18s/step - loss: 2.0146 - time_distributed_loss: 0.7083 - time_distributed_1_loss: 3.3209 - val_loss: 3.7150 - val_time_distributed_loss: 2.7657 - val_time_distributed_1_loss: 4.6643\n",
      "Epoch 32/50\n",
      "504/504 [==============================] - 9108s 18s/step - loss: 1.9864 - time_distributed_loss: 0.6770 - time_distributed_1_loss: 3.2957 - val_loss: 3.7257 - val_time_distributed_loss: 2.7770 - val_time_distributed_1_loss: 4.6745\n",
      "Epoch 33/50\n",
      "504/504 [==============================] - 9024s 18s/step - loss: 1.9587 - time_distributed_loss: 0.6463 - time_distributed_1_loss: 3.2712 - val_loss: 3.7452 - val_time_distributed_loss: 2.7966 - val_time_distributed_1_loss: 4.6938\n",
      "Epoch 34/50\n",
      "504/504 [==============================] - 9057s 18s/step - loss: 1.9320 - time_distributed_loss: 0.6165 - time_distributed_1_loss: 3.2476 - val_loss: 3.7634 - val_time_distributed_loss: 2.8223 - val_time_distributed_1_loss: 4.7045\n",
      "Epoch 35/50\n",
      "504/504 [==============================] - 9115s 18s/step - loss: 1.9071 - time_distributed_loss: 0.5900 - time_distributed_1_loss: 3.2243 - val_loss: 3.7807 - val_time_distributed_loss: 2.8440 - val_time_distributed_1_loss: 4.7173\n",
      "Epoch 36/50\n",
      "504/504 [==============================] - 9115s 18s/step - loss: 1.8827 - time_distributed_loss: 0.5636 - time_distributed_1_loss: 3.2018 - val_loss: 3.7985 - val_time_distributed_loss: 2.8662 - val_time_distributed_1_loss: 4.7309\n",
      "Epoch 37/50\n",
      "504/504 [==============================] - 9081s 18s/step - loss: 1.8584 - time_distributed_loss: 0.5366 - time_distributed_1_loss: 3.1802 - val_loss: 3.8150 - val_time_distributed_loss: 2.8878 - val_time_distributed_1_loss: 4.7423\n",
      "Epoch 38/50\n",
      "504/504 [==============================] - 9295s 18s/step - loss: 1.8339 - time_distributed_loss: 0.5089 - time_distributed_1_loss: 3.1590 - val_loss: 3.8319 - val_time_distributed_loss: 2.9047 - val_time_distributed_1_loss: 4.7590\n",
      "Epoch 39/50\n",
      "504/504 [==============================] - 9114s 18s/step - loss: 1.8117 - time_distributed_loss: 0.4852 - time_distributed_1_loss: 3.1381 - val_loss: 3.8524 - val_time_distributed_loss: 2.9354 - val_time_distributed_1_loss: 4.7694\n",
      "Epoch 40/50\n",
      "504/504 [==============================] - 9172s 18s/step - loss: 1.7910 - time_distributed_loss: 0.4636 - time_distributed_1_loss: 3.1184 - val_loss: 3.8710 - val_time_distributed_loss: 2.9519 - val_time_distributed_1_loss: 4.7901\n",
      "Epoch 41/50\n",
      "504/504 [==============================] - 9208s 18s/step - loss: 1.7695 - time_distributed_loss: 0.4408 - time_distributed_1_loss: 3.0983 - val_loss: 3.8916 - val_time_distributed_loss: 2.9809 - val_time_distributed_1_loss: 4.8023\n",
      "Epoch 42/50\n",
      "504/504 [==============================] - 9156s 18s/step - loss: 1.7498 - time_distributed_loss: 0.4201 - time_distributed_1_loss: 3.0795 - val_loss: 3.9073 - val_time_distributed_loss: 3.0018 - val_time_distributed_1_loss: 4.8128\n",
      "Epoch 43/50\n",
      "504/504 [==============================] - 9061s 18s/step - loss: 1.7306 - time_distributed_loss: 0.4006 - time_distributed_1_loss: 3.0606 - val_loss: 3.9280 - val_time_distributed_loss: 3.0307 - val_time_distributed_1_loss: 4.8253\n",
      "Epoch 44/50\n",
      "504/504 [==============================] - 9083s 18s/step - loss: 1.7116 - time_distributed_loss: 0.3807 - time_distributed_1_loss: 3.0425 - val_loss: 3.9486 - val_time_distributed_loss: 3.0541 - val_time_distributed_1_loss: 4.8431\n",
      "Epoch 45/50\n",
      "504/504 [==============================] - 9190s 18s/step - loss: 1.6936 - time_distributed_loss: 0.3624 - time_distributed_1_loss: 3.0247 - val_loss: 3.9678 - val_time_distributed_loss: 3.0768 - val_time_distributed_1_loss: 4.8587\n",
      "Epoch 46/50\n",
      "504/504 [==============================] - 9099s 18s/step - loss: 1.6762 - time_distributed_loss: 0.3447 - time_distributed_1_loss: 3.0076 - val_loss: 3.9866 - val_time_distributed_loss: 3.1036 - val_time_distributed_1_loss: 4.8697\n",
      "Epoch 47/50\n",
      "504/504 [==============================] - 9231s 18s/step - loss: 1.6593 - time_distributed_loss: 0.3279 - time_distributed_1_loss: 2.9907 - val_loss: 4.0042 - val_time_distributed_loss: 3.1266 - val_time_distributed_1_loss: 4.8819\n",
      "Epoch 48/50\n",
      "504/504 [==============================] - 9131s 18s/step - loss: 1.6433 - time_distributed_loss: 0.3125 - time_distributed_1_loss: 2.9742 - val_loss: 4.0265 - val_time_distributed_loss: 3.1548 - val_time_distributed_1_loss: 4.8981\n",
      "Epoch 49/50\n",
      "504/504 [==============================] - 9145s 18s/step - loss: 1.6274 - time_distributed_loss: 0.2970 - time_distributed_1_loss: 2.9579 - val_loss: 4.0372 - val_time_distributed_loss: 3.1683 - val_time_distributed_1_loss: 4.9061\n",
      "Epoch 50/50\n",
      "504/504 [==============================] - 9203s 18s/step - loss: 1.6120 - time_distributed_loss: 0.2816 - time_distributed_1_loss: 2.9425 - val_loss: 4.0530 - val_time_distributed_loss: 3.1835 - val_time_distributed_1_loss: 4.9225\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "max_title_len = 20\n",
    "max_body_len = 200\n",
    "input_len = max_title_len + max_body_len + 1\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove HTML links\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove links starting with http\n",
    "    text = re.sub(r'www\\S+', '', text)   # Remove links starting with www\n",
    "\n",
    "    # Replace punctuations and numbers with a space (except for '.', ',', '!', '?' and numbers)\n",
    "    text = re.sub('[^a-zA-Z0-9.,!?]', ' ', text)\n",
    "\n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Preprocess titles and bodies using the preprocess_text function\n",
    "preprocessed_titles = ['<start> ' + preprocess_text(text) + ' <end>' for text in df['title']]\n",
    "preprocessed_bodies = ['<start> ' + preprocess_text(text) + ' <end>' for text in df['body']]\n",
    "\n",
    "# We should ensure that both title and body are not empty after preprocessing\n",
    "filtered_data = [(title, body) for title, body in zip(preprocessed_titles, preprocessed_bodies) if title and body]\n",
    "\n",
    "separator_token = \"<sep>\"\n",
    "texts = [title + ' ' + separator_token + ' ' + body for title, body in filtered_data]\n",
    "texts = list(filter(None, texts))\n",
    "\n",
    "tokenizer = Tokenizer(filters='', lower=False)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "total_unique_words = len(tokenizer.word_index)\n",
    "max_words = int(total_unique_words * 1.0)\n",
    "tokenizer = Tokenizer(num_words=max_words, filters='', lower=False)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "\n",
    "\n",
    "# Add the separator token to the tokenizer's word index\n",
    "if separator_token not in tokenizer.word_index:\n",
    "    tokenizer.word_index[separator_token] = max_words\n",
    "    tokenizer.index_word[max_words] = separator_token\n",
    "\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "if '<start>' not in tokenizer.word_index:\n",
    "    tokenizer.word_index['<start>'] = max_words - 1\n",
    "    tokenizer.index_word[max_words - 1] = '<start>'\n",
    "if '<end>' not in tokenizer.word_index:\n",
    "    tokenizer.word_index['<end>'] = max_words\n",
    "    tokenizer.index_word[max_words] = '<end>'\n",
    "\n",
    "\n",
    "# Generate input sequences using the tokenizer\n",
    "input_sequences = tokenizer.texts_to_sequences(texts)\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=input_len, padding='post', truncating='post')\n",
    "\n",
    "input_sequences = np.array([seq for seq in input_sequences if 1 in seq], dtype=np.int32)\n",
    "\n",
    "\n",
    "missing_start_count = 0\n",
    "missing_end_count = 0\n",
    "for seq in input_sequences:\n",
    "    if tokenizer.word_index['<start>'] not in seq:\n",
    "        missing_start_count += 1\n",
    "    if tokenizer.word_index['<end>'] not in seq:\n",
    "        missing_end_count += 1\n",
    "\n",
    "print(f\"Missing start token in {missing_start_count} sequences.\")\n",
    "print(f\"Missing end token in {missing_end_count} sequences.\")\n",
    "\n",
    "\n",
    "# Find the separator token's index in each sequence, will set the separator index to the last index of the title part if it's not found in the sequence.\n",
    "separator_indices = []\n",
    "missing_separator_count = 0\n",
    "for seq in input_sequences:\n",
    "    separator_index = np.where(seq == tokenizer.word_index[separator_token])[0]\n",
    "    if separator_index.size > 0:\n",
    "        separator_indices.append(separator_index[0])\n",
    "    else:\n",
    "        separator_indices.append(max_title_len - 1)\n",
    "        missing_separator_count += 1\n",
    "\n",
    "separator_indices = np.array(separator_indices)\n",
    "print(f\"Missing separator token in {missing_separator_count} sequences.\")\n",
    "\n",
    "# Split the dataset into title and body parts\n",
    "input_sequences_title = np.array([seq[:idx] for seq, idx in zip(input_sequences, separator_indices)], dtype=object)\n",
    "input_sequences_body = np.array([seq[idx+1:] for seq, idx in zip(input_sequences, separator_indices)], dtype=object)\n",
    "\n",
    "# Pad the sequences for title and body\n",
    "input_sequences_title = pad_sequences(input_sequences_title, maxlen=max_title_len, padding='post', truncating='post')\n",
    "input_sequences_body = pad_sequences(input_sequences_body, maxlen=max_body_len, padding='post', truncating='post')\n",
    "\n",
    "# Concatenate title and body sequences with the separator token for the encoder input\n",
    "input_sequences_combined = np.hstack([input_sequences_title, np.full((input_sequences_title.shape[0], 1), tokenizer.word_index[separator_token]), input_sequences_body])\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train_combined, X_val_combined = train_test_split(input_sequences_combined, test_size=0.1, random_state=42)\n",
    "X_train_title, X_val_title = train_test_split(input_sequences_title, test_size=0.1, random_state=42)\n",
    "X_train_body, X_val_body = train_test_split(input_sequences_body, test_size=0.1, random_state=42)\n",
    "\n",
    "# Multi-task learning model\n",
    "latent_dim = 256\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "encoder_emb_layer = Embedding(total_words, latent_dim)\n",
    "encoder_emb = encoder_emb_layer(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "_, state_h, state_c = encoder_lstm(encoder_emb)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Define the encoder model\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Title Decoder\n",
    "decoder_inputs_title = Input(shape=(None,))\n",
    "decoder_emb_layer_title = Embedding(total_words, latent_dim)\n",
    "decoder_emb_title = decoder_emb_layer_title(decoder_inputs_title)\n",
    "decoder_lstm_title = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs_title, _, _ = decoder_lstm_title(decoder_emb_title, initial_state=encoder_states)\n",
    "decoder_dense_title = TimeDistributed(Dense(total_words, activation='softmax'))\n",
    "decoder_outputs_title = decoder_dense_title(decoder_outputs_title)\n",
    "\n",
    "# Body Decoder\n",
    "decoder_inputs_body = Input(shape=(None,))\n",
    "decoder_emb_layer_body = Embedding(total_words, latent_dim)\n",
    "decoder_emb_body = decoder_emb_layer_body(decoder_inputs_body)\n",
    "decoder_lstm_body = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs_body, _, _ = decoder_lstm_body(decoder_emb_body, initial_state=encoder_states)\n",
    "decoder_dense_body = TimeDistributed(Dense(total_words, activation='softmax'))\n",
    "decoder_outputs_body = decoder_dense_body(decoder_outputs_body)\n",
    "\n",
    "# Define the multi-task model\n",
    "model = Model([encoder_inputs, decoder_inputs_title, decoder_inputs_body], [decoder_outputs_title, decoder_outputs_body])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', loss_weights=[0.5, 0.5])\n",
    "print(\"X_train_title shape:\", X_train_title.shape)\n",
    "print(\"X_train_body shape:\", X_train_body.shape)\n",
    " \n",
    "# Train the seq2seq model\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "validation_split = 0.1\n",
    "\n",
    "model.fit([X_train_combined, X_train_title[:, :-1], X_train_body[:, :-1]], [X_train_title[:, 1:], X_train_body[:, 1:]],\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=validation_split,\n",
    "          )\n",
    "\n",
    "# Title Decoder Inference\n",
    "decoder_state_input_h_title = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c_title = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs_title = [decoder_state_input_h_title, decoder_state_input_c_title]\n",
    "decoder_emb_title = decoder_emb_layer_title(decoder_inputs_title)\n",
    "decoder_outputs_title, state_h_title, state_c_title = decoder_lstm_title(decoder_emb_title, initial_state=decoder_states_inputs_title)\n",
    "decoder_states_title = [state_h_title, state_c_title]\n",
    "decoder_outputs_title = decoder_dense_title(decoder_outputs_title)\n",
    "decoder_model_title = Model([decoder_inputs_title] + decoder_states_inputs_title, [decoder_outputs_title] + decoder_states_title)\n",
    "\n",
    "# Body Decoder Inference\n",
    "decoder_state_input_h_body = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c_body = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs_body = [decoder_state_input_h_body, decoder_state_input_c_body]\n",
    "decoder_emb_body = decoder_emb_layer_body(decoder_inputs_body)\n",
    "decoder_outputs_body, state_h_body, state_c_body = decoder_lstm_body(decoder_emb_body, initial_state=decoder_states_inputs_body)\n",
    "decoder_states_body = [state_h_body, state_c_body]\n",
    "decoder_outputs_body = decoder_dense_body(decoder_outputs_body)\n",
    "decoder_model_body = Model([decoder_inputs_body] + decoder_states_inputs_body, [decoder_outputs_body] + decoder_states_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07142219-4ac2-41a4-981d-68c246c5eba7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The script contains functions for decoding sequences into titles and bodies, checking grammar, computing rewards for generated titles and bodies, and computing the total reward. The reward is based on several factors such as the presence of certain keywords, sentiment score, structure of the text, and number of grammar errors. Note: right now it is not concered with maximising the reward, only to see as a baseline to be compared with after PPO training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "576134b4-7670-4424-8c09-3ac502a69eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-Levenshtein in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: Levenshtein==0.21.0 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from python-Levenshtein) (0.21.0)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in c:\\users\\public\\downloads\\anaconda3\\lib\\site-packages (from Levenshtein==0.21.0->python-Levenshtein) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "# To ensure UTF-8 encoding is used\n",
    "import locale\n",
    "\n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding\n",
    "\n",
    "# Importing the Levenshtein distance for grammar check\n",
    "import Levenshtein\n",
    "!pip install python-Levenshtein\n",
    "\n",
    "# Function to decode the title from the input sequence\n",
    "def decode_sequence_title(input_seq):\n",
    "    # Predict the state values using the encoder model and the input sequence\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Initialize the target sequence with the start token\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = tokenizer.word_index['<start>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    # Loop until the end token is predicted or the maximum length is reached\n",
    "    while not stop_condition:\n",
    "        # Predict the next token and the state values\n",
    "        output_tokens, h, c = decoder_model_title.predict([target_seq] + states_value)\n",
    "        # The token with the highest probability is selected\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = tokenizer.index_word[sampled_token_index]\n",
    "        \n",
    "        # If the end token is predicted or the maximum length is reached, stop\n",
    "        if sampled_char == '<end>' or len(decoded_sentence) > max_title_len:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence += ' ' + sampled_char\n",
    "\n",
    "        # Update the target sequence with the predicted token\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        # Update the state values\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence.strip()\n",
    "\n",
    "# Same function as above but for the body\n",
    "def decode_sequence_body(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = tokenizer.word_index['<start>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model_body.predict([target_seq] + states_value)\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = tokenizer.index_word[sampled_token_index]\n",
    "        \n",
    "        if sampled_char == '<end>' or len(decoded_sentence) > max_body_len:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence += ' ' + sampled_char\n",
    "\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence.strip()\n",
    "\n",
    "# Function to check grammar in a text using Levenshtein distance\n",
    "def grammar_check(text):\n",
    "    tb = TextBlob(text)\n",
    "    corrected_text = tb.correct()\n",
    "    return Levenshtein.distance(str(corrected_text), text)\n",
    "\n",
    "\n",
    "def compute_title_reward(preprocessed_title):\n",
    "    title_reward = 0\n",
    "    title_keywords = {'aita', 'wibta', 'am i the'}\n",
    "    tokens = {token.text.lower() for token in nlp(preprocessed_title)}\n",
    "    title_present = bool(title_keywords.intersection(tokens))\n",
    "    if title_present:\n",
    "        title_reward += 1\n",
    "\n",
    "    grammar_errors = grammar_check(preprocessed_title)\n",
    "    grammar_reward = 0\n",
    "    if grammar_errors == 0:\n",
    "        grammar_reward += 1\n",
    "\n",
    "    w_title, w_grammar = 0.5, 0.5\n",
    "    reward = (w_title * title_reward + w_grammar * grammar_reward)\n",
    "    reward /= (w_title + w_grammar)\n",
    "\n",
    "    return reward\n",
    "\n",
    "def compute_body_reward(preprocessed_body):\n",
    "    body_reward = 0\n",
    "    body = preprocessed_body\n",
    "\n",
    "    sentiment_score = sia.polarity_scores(body)\n",
    "    sentiment_reward = 1 if abs(sentiment_score['compound']) >= 0.75 else 0\n",
    "\n",
    "    situation_keywords = {'situation', 'happened', 'issue'}\n",
    "    action_keywords = {'action', 'did', 'took'}\n",
    "    justifiable_keywords = {'justifiable', 'wrong', 'right'}\n",
    "\n",
    "    tokens = set(token.text for token in nlp(preprocessed_body))\n",
    "    situation_present = bool(situation_keywords.intersection(tokens))\n",
    "    action_present = bool(action_keywords.intersection(tokens))\n",
    "    justifiable_present = bool(justifiable_keywords.intersection(tokens))\n",
    "    structure_reward = sum([situation_present, action_present, justifiable_present])\n",
    "\n",
    "    grammar_errors = grammar_check(body)\n",
    "    grammar_reward = 1 if grammar_errors == 0 else 0\n",
    "\n",
    "    w_sentiment, w_structure, w_grammar = 1, 3, 1\n",
    "    reward = (w_sentiment * sentiment_reward +\n",
    "              w_structure * structure_reward +\n",
    "              w_grammar * grammar_reward)\n",
    "    reward /= (w_sentiment + w_structure + w_grammar)\n",
    "\n",
    "    return reward\n",
    "\n",
    "\n",
    "\n",
    "def compute_reward( generated_title, generated_body):\n",
    "    # Preprocess the title and body\n",
    "    preprocessed_title = preprocess_text(generated_title)\n",
    "    preprocessed_body = preprocess_text(generated_body)\n",
    "\n",
    "    # Compute rewards for the title and body\n",
    "    title_reward = compute_title_reward(preprocessed_title)\n",
    "    body_reward = compute_body_reward(preprocessed_body)\n",
    "\n",
    "    # Combine the title and body rewards with appropriate weights\n",
    "    w_title, w_body = 0.5, 0.5\n",
    "    reward = (w_title * title_reward + w_body * body_reward)\n",
    "    reward /= (w_title + w_body)\n",
    "\n",
    "    return reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4def4051-5ff2-47ed-bec9-c6dbe8d41b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Generated Title: aita for smoking inside?\n",
      "Generated Body: hello reddit AITA smoke smoke? i F liked smoking because it looked nice \n",
      "Reward: 0.25\n"
     ]
    }
   ],
   "source": [
    "def generate_text(input_text):\n",
    "    input_sequence = tokenizer.texts_to_sequences([input_text])\n",
    "    input_sequence = pad_sequences(input_sequence, maxlen=input_len, padding='post', truncating='post')\n",
    "    generated_title = decode_sequence_title(input_sequence)\n",
    "    generated_body = decode_sequence_body(input_sequence)\n",
    "    return generated_title, generated_body\n",
    "\n",
    "def process_example(input_text):\n",
    "    generated_title, generated_body = generate_text(input_text)\n",
    "    reward = compute_reward(generated_title, generated_body)\n",
    "    return generated_title, generated_body, reward\n",
    "\n",
    "# Example usage\n",
    "input_text = \"\"\n",
    "generated_title, generated_body, reward = process_example(input_text)\n",
    "gprint(\"Generated Title:\", generated_title)\n",
    "print(\"Generated Body:\", generated_body)\n",
    "print(\"Reward:\", reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166fc33e-f637-47e5-b250-7d1dc4c1c2cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "ppo section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ff3312-edb2-4e54-af23-267699d51568",
   "metadata": {},
   "source": [
    "This code includes libraries and classes necessary to set up a reinforcement learning environment for the task of text generation, specifically for generating titles and bodies of texts. The code uses the Proximal Policy Optimization (PPO) reinforcement learning algorithm to generate text and uses the gym library to set up the reinforcement learning environment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fad9bb3-0ba7-4597-ab26-21a84adb3e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\da476/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\da476/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\da476/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "import gym\n",
    "from gym import spaces\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import language_tool_python\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback\n",
    "import nltk\n",
    "import numpy as np\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import language_tool_python\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "max_episode_length = 150  #max_episode_length is a term commonly used in reinforcement learning, referring to the maximum number of steps (or actions) allowed in each episode of the learning environment.\n",
    "\n",
    "\n",
    "\n",
    "def grammar_check(sequence):\n",
    "    matches = tool.check(sequence)\n",
    "    return len(matches)\n",
    "\n",
    "def preprocess_for_ppo(generated_text):\n",
    "    tokenized_text = preprocess_text_lda(generated_text)\n",
    "    return tokenized_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "class TextGenerationEnv(gym.Env):\n",
    "    def __init__(self, model, tokenizer, max_title_len, max_body_len, max_episode_length, preprocess_for_ppo):\n",
    "        super(TextGenerationEnv, self).__init__()\n",
    "        self.preprocess_fn = preprocess_for_ppo\n",
    "        self.max_sequence_len = max_title_len + max_body_len\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_title_len = max_title_len\n",
    "        self.max_body_len = max_body_len\n",
    "        self.max_episode_length = max_episode_length\n",
    "        self.action_space = spaces.Discrete(vocab_size)\n",
    "        self.observation_space = spaces.Box(low=0, high=vocab_size - 1, shape=(max_title_len + max_body_len,), dtype=np.int32)\n",
    "        \n",
    "    def reset(self):\n",
    "        self.current_text = self.generate_initial_state()\n",
    "        self.current_title = self.current_text[:self.max_title_len]\n",
    "        self.current_step = 0\n",
    "        print(\"Reset: current_text shape\", self.current_text.shape)  # Add this line\n",
    "        return self.current_text\n",
    "        \n",
    "    def generate_initial_state(self):\n",
    "        initial_title = np.random.randint(1, vocab_size, self.max_title_len - 1)\n",
    "        initial_body = np.random.randint(1, vocab_size, self.max_body_len)\n",
    "        initial_text = np.concatenate((initial_title, [self.tokenizer.word_index[separator_token]], initial_body))\n",
    "        return initial_text\n",
    "\n",
    "    def step(self, action: np.ndarray):\n",
    "        token = action\n",
    "        self.current_text[:-1] = self.current_text[1:]\n",
    "        self.current_text[-1] = token\n",
    "\n",
    "        self.current_step += 1\n",
    "        generated_text = self.tokenizer.sequences_to_texts([self.current_text])[0]\n",
    "\n",
    "        # Separate title and body using the separator token\n",
    "        generated_text_split = generated_text.split(separator_token, 1)\n",
    "        if len(generated_text_split) == 2:\n",
    "            title, body = generated_text_split\n",
    "        else:\n",
    "            half_length = len(generated_text) // 2\n",
    "            title = generated_text[:half_length]\n",
    "            body = generated_text[half_length:]\n",
    "\n",
    "        # Concatenate title and body without the separator token\n",
    "        final_generated_text = title + \" \" + body\n",
    "        preprocessed_text = self.preprocess_fn(generated_text)\n",
    "\n",
    "        # Compute the rewards for title and body\n",
    "        title_reward = self.compute_title_reward(title)\n",
    "        body_reward = self.compute_body_reward(body)\n",
    "\n",
    "        # Combine the weighted scores to obtain the final reward\n",
    "        w_title, w_body = 0.5, 0.5\n",
    "        reward = (w_title * title_reward + w_body * body_reward)\n",
    "        reward /= (w_title + w_body)\n",
    "\n",
    "        # Fit the model using the concatenated title and body\n",
    "        Xy = np.expand_dims(self.current_text, axis=0)\n",
    "        #print(\"Xy shape:\", Xy.shape)\n",
    "        self.model.fit(Xy, Xy, epochs=1, verbose=0, batch_size=1)\n",
    "\n",
    "        done = self.current_step >= self.max_episode_length\n",
    "\n",
    "        return self.current_text, reward, done, {} \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def compute_title_reward(self, preprocessed_title):\n",
    "        title_reward = 0\n",
    "        title_keywords = ['aita', 'wibta', 'am i the']\n",
    "        title_present = any(keyword in preprocessed_title for keyword in title_keywords)\n",
    "        if title_present:\n",
    "            title_reward += 1\n",
    "\n",
    "        grammar_errors = grammar_check(' '.join(preprocessed_title))\n",
    "        grammar_reward = 0\n",
    "        if grammar_errors == 0:\n",
    "            grammar_reward += 1\n",
    "\n",
    "        # Combine the weighted scores to obtain the final reward\n",
    "        w_title, w_grammar = 0.5, 0.5\n",
    "        reward = (w_title * title_reward + w_grammar * grammar_reward)\n",
    "        reward /= (w_title + w_grammar)\n",
    "\n",
    "        return reward\n",
    "\n",
    "    \n",
    "    def compute_body_reward(self, preprocessed_body):\n",
    "        body_reward = 0\n",
    "        body = ' '.join(preprocessed_body)\n",
    "\n",
    "        # Sentiment analysis reward\n",
    "        sentiment_score = sia.polarity_scores(body)\n",
    "        sentiment_reward = 1 if abs(sentiment_score['compound']) >= 0.75 else 0\n",
    "\n",
    "        # Topical coherence reward\n",
    "        coherence_reward = self.compute_topic_coherence(body)\n",
    "\n",
    "        # Post structure reward\n",
    "        situation_keywords = ['situation', 'happened', 'issue']\n",
    "        action_keywords = ['action', 'did', 'took']\n",
    "        justifiable_keywords = ['justifiable', 'wrong', 'right']\n",
    "        situation_present = any(keyword in preprocessed_body for keyword in situation_keywords)\n",
    "        action_present = any(keyword in preprocessed_body for keyword in action_keywords)\n",
    "        justifiable_present = any(keyword in preprocessed_body for keyword in justifiable_keywords)\n",
    "        structure_reward = sum([situation_present, action_present, justifiable_present])\n",
    "\n",
    "        # Grammar and fluency reward\n",
    "        grammar_errors = grammar_check(body)\n",
    "        grammar_reward = 1 if grammar_errors == 0 else 0\n",
    "\n",
    "        # Combine the weighted scores to obtain the final reward\n",
    "        w_sentiment, w_coherence, w_structure, w_grammar = 1, 1, 3, 1\n",
    "        reward = (w_sentiment * sentiment_reward +\n",
    "                  w_coherence * coherence_reward +\n",
    "                  w_structure * structure_reward +\n",
    "                  w_grammar * grammar_reward)\n",
    "        reward /= (w_sentiment + w_coherence + w_structure + w_grammar)\n",
    "\n",
    "        return reward\n",
    "\n",
    "\n",
    "    \n",
    "    def compute_topic_coherence(self, body):\n",
    "        # Preprocess the title and body\n",
    "        title = self.tokenizer.sequences_to_texts([self.current_title])[0]\n",
    "        tokenized_title = preprocess_text_lda(title)\n",
    "        tokenized_body = preprocess_text_lda(body)\n",
    "        \n",
    "        # Combine the tokenized title and body\n",
    "        tokenized_sequence = tokenized_title + tokenized_body\n",
    "\n",
    "        # Create a bag-of-words representation\n",
    "        bow_sequence = dictionary.doc2bow(tokenized_sequence)\n",
    "\n",
    "        # Get topic distribution for the generated sequence\n",
    "        topic_dist = lda_model.get_document_topics(bow_sequence)\n",
    "\n",
    "        # Compute coherence based on the highest probability topic\n",
    "        coherence = max([prob for _, prob in topic_dist])\n",
    "\n",
    "        return coherence\n",
    "    \n",
    "    def compute_reward(self, generated_text):\n",
    "        # Split the generated text using the separator token\n",
    "        title, body = generated_text.split(separator_token)\n",
    "\n",
    "        # Preprocess the title and body\n",
    "        preprocessed_title = preprocess(title)\n",
    "        preprocessed_body = preprocess(body)\n",
    "\n",
    "        # Compute rewards for the title and body\n",
    "        title_reward = self.compute_title_reward(preprocessed_title)\n",
    "        body_reward = self.compute_body_reward(preprocessed_body)\n",
    "\n",
    "        # Combine the title and body rewards with appropriate weights\n",
    "        w_title, w_body = 0.5, 0.5\n",
    "        reward = (w_title * title_reward + w_body * body_reward)\n",
    "        reward /= (w_title + w_body)\n",
    "\n",
    "        return reward\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16df836e-5c2c-436b-84d2-6fa597655ab5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 41>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenized_text\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Create a list of tokenized titles and bodies\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m tokenized_titles \u001b[38;5;241m=\u001b[39m [preprocess_text_lda(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     42\u001b[0m tokenized_bodies \u001b[38;5;241m=\u001b[39m [preprocess_text_lda(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Combine the tokenized titles and bodies into a single list of documents\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#Topical coherence\n",
    "\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Preprocess the text\n",
    "def remove_tags(text):\n",
    "    TAG_RE = re.compile(r'<[^>]+>')\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "def preprocess_text_lda(text):\n",
    "    corpus = []\n",
    "    pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n",
    "\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove HTML tags\n",
    "    text = remove_tags(text)\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "\n",
    "    # Remove single characters\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "\n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    text = pattern.sub('', text)\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokenized_text = word_tokenize(text)\n",
    "\n",
    "    return tokenized_text\n",
    "\n",
    "\n",
    "# Create a list of tokenized titles and bodies\n",
    "tokenized_titles = [preprocess_text_lda(text) for text in df['title']]\n",
    "tokenized_bodies = [preprocess_text_lda(text) for text in df['body']]\n",
    "\n",
    "# Combine the tokenized titles and bodies into a single list of documents\n",
    "documents = [title + body for title, body in zip(tokenized_titles, tokenized_bodies)]\n",
    "\n",
    "\n",
    "# Create a dictionary representation of the documents\n",
    "dictionary = Dictionary(documents)\n",
    "\n",
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.5)\n",
    "\n",
    "# Create a bag-of-words representation of the documents\n",
    "corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
    "\n",
    "\n",
    "# Train the LDA model with increased passes and iterations\n",
    "num_topics = 10  # You can choose the number of topics based on your dataset\n",
    "passes = 20  # Increase the number of passes\n",
    "iterations = 200  # Increase the number of iterations\n",
    "lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, random_state=42, passes=passes, iterations=iterations)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342f275d-3e79-4921-bceb-1e811d464ce9",
   "metadata": {},
   "source": [
    "This script is responsible for training, evaluating, and testing a Proximal Policy Optimization (PPO) reinforcement learning agent that generates text in a custom environment defined as TextGenerationEnv.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "085e3a2a-8181-41d9-9929-2cbd116933c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EvalCallback\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Create a training environment\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m train_env \u001b[38;5;241m=\u001b[39m TextGenerationEnv(\u001b[43mmodel\u001b[49m, tokenizer, max_title_len, max_body_len, max_episode_length, preprocess_for_ppo)\n\u001b[0;32m      8\u001b[0m train_env \u001b[38;5;241m=\u001b[39m DummyVecEnv([\u001b[38;5;28;01mlambda\u001b[39;00m: train_env])\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Train the PPO agent\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "\n",
    "# Create a training environment\n",
    "train_env = TextGenerationEnv(model, tokenizer, max_title_len, max_body_len, max_episode_length, preprocess_for_ppo)\n",
    "train_env = DummyVecEnv([lambda: train_env])\n",
    "\n",
    "# Train the PPO agent\n",
    "ppo_agent = PPO(\"MlpPolicy\", train_env, verbose=1)\n",
    "ppo_agent.learn(total_timesteps=50000)  # Train for 50,000 time steps\n",
    "\n",
    "# Create an evaluation environment\n",
    "eval_env = TextGenerationEnv(model, tokenizer, max_title_len, max_body_len, max_episode_length, preprocess_for_ppo)\n",
    "eval_env = DummyVecEnv([lambda: eval_env])\n",
    "\n",
    "# Create an EvalCallback\n",
    "eval_callback = EvalCallback(eval_env, best_model_save_path='./models/',\n",
    "                             log_path='./logs/', eval_freq=1000,\n",
    "                             deterministic=True, render=False)\n",
    "\n",
    "# Perform evaluation after training is completed\n",
    "ppo_agent.learn(total_timesteps=1, callback=eval_callback)  # Run learn method for 1 time step to trigger the evaluation\n",
    "\n",
    "\n",
    "\n",
    "# Load the best model\n",
    "best_agent = PPO.load(save_path)\n",
    "\n",
    "# Generate text using the trained agent\n",
    "obs = env.reset()\n",
    "done = False\n",
    "generated_title = []\n",
    "generated_body = []\n",
    "\n",
    "while not done:\n",
    "    action, _states = best_agent.predict(obs)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    generated_title.append(tokenizer.sequences_to_texts([obs['title']])[0])\n",
    "    generated_body.append(tokenizer.sequences_to_texts([obs['body']])[0])\n",
    "\n",
    "generated_title = \" \".join(generated_title)\n",
    "generated_body = \" \".join(generated_body)\n",
    "print(\"Generated title:\", generated_title)\n",
    "print(\"Generated body:\", generated_body)\n",
    "\n",
    "# Evaluate the agent\n",
    "total_rewards = []\n",
    "for _ in range(5):  # You can adjust the number of evaluation episodes\n",
    "    obs = eval_env.reset()\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    while not done:\n",
    "        action, _ = best_agent.predict(obs, deterministic=True)\n",
    "        obs, reward, done, _ = eval_env.step(action)\n",
    "        episode_reward += reward\n",
    "    total_rewards.append(episode_reward)\n",
    "\n",
    "avg_reward = np.mean(total_rewards)\n",
    "print(f\"Average reward for the best model: {avg_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4d2ee2-ead6-46a0-8400-e9f4731cc6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "class SaveBestModelCallback(BaseCallback):\n",
    "    def __init__(self, save_path, eval_env, check_freq, verbose=0):\n",
    "        super(SaveBestModelCallback, self).__init__(verbose)\n",
    "        self.save_path = save_path\n",
    "        self.eval_env = eval_env\n",
    "        self.check_freq = check_freq\n",
    "        self.best_reward = -float(\"inf\")\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            # Evaluate the current model\n",
    "            total_rewards = []\n",
    "            for _ in range(5):  # You can adjust the number of evaluation episodes\n",
    "                obs = self.eval_env.reset()\n",
    "                done = False\n",
    "                episode_reward = 0\n",
    "                while not done:\n",
    "                    action, _ = self.model.predict(obs, deterministic=True)\n",
    "                    obs, reward, done, _ = self.eval_env.step(action)\n",
    "                    episode_reward += reward\n",
    "                total_rewards.append(episode_reward)\n",
    "\n",
    "            avg_reward = np.mean(total_rewards)\n",
    "            print(f\"Average reward after {self.n_calls} steps: {avg_reward}\")  # Add this line to print the average reward\n",
    "            if avg_reward > self.best_reward:\n",
    "                self.best_reward = avg_reward\n",
    "                self.model.save(self.save_path)\n",
    "                if self.verbose:\n",
    "                    print(f\"New best model with reward {avg_reward}, model saved.\")\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "save_path = \"best_model\"\n",
    "eval_env = TextGenerationEnv(model, tokenizer, max_sequence_len, max_episode_length)\n",
    "eval_env = DummyVecEnv([lambda: eval_env])\n",
    "callback = SaveBestModelCallback(save_path, eval_env, check_freq=5000)\n",
    "\n",
    "\n",
    "for i, sample in enumerate(generated_samples):\n",
    "    print(f\"Sample {i + 1}:\")\n",
    "    print(sample)\n",
    "    print(\"-\" * 40)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
